ID,NAME,TITLE,DATE,LOCATION,GITHUB,MOTTO,WIN,TEXT
motleymoves,üèÉ MotleyMoves,UCM Final Project,May 2019,"Merced, California",https://github.com/plebeiathon/MotleyMoves,"Expediting Modesto Moves' transition from pen-and-paper to a modern all-in-one platform",,"<h3>The Idea</h3><p>Modesto Moves is a nonprofit training club with 250+ participants across Modesto, Ripon, and Manteca ‚Äî but they were running everything on pen and paper. We built MotleyMoves to digitize the entire operation: event planning, participant tracking, check-in/check-out, medical records, and real-time race mapping, all in one mobile-friendly web app.</p><h3>How It Works</h3><p>A serverless C#.NET Azure Function App serves as the API layer, connecting an Azure SQL Database to an HTML/CSS/JS front-end. Google Sign-In handles auth, MapBox powers interactive race course maps with draggable markers for bathrooms, refreshments, and parking, and FullCalendar displays upcoming events. Admins can create events, draw race routes on a map, track attendance with check-in/check-out timestamps, and view participant medical info ‚Äî all from the browser. We enrolled in Azure Cloud for Nonprofits ($5,000/year in credits) to keep the back-end running at zero cost.</p><h3>The Grind</h3><p>The C# back-end alone has 15+ Azure Function endpoints handling everything from race point CRUD to real-time GPS position updates to medical record management. Safety was embedded at every layer ‚Äî medical info, emergency contacts, condition tracking ‚Äî because these are real people running real races. We redesigned the entire administrative workflow, built it for scalability to neighboring communities, and added an attendance incentive system to keep participants coming back.</p>"
azuremlops,‚ö° Azure ML Operationalization,"MSFT Internship",May 2019,"Bellevue, Washington",https://github.com/Mutilar/AzureMLOperationalization,"Streamlining and expediting CI/CD workflows",,"<h3>The Idea</h3><p>Data scientists shouldn't have to wait on shared build agents just to validate a Jupyter notebook. Azure ML Operationalization replaces agent-bound CI/CD with a fully agentless pipeline ‚Äî Azure DevOps triggers an Azure Service Bus message, which fires an Azure Function that submits notebook Runs directly to Azure ML Compute. No queuing behind other builds, no agent pool contention, and full telemetry surfaced as DevOps Test Runs so failures are debuggable right in the pipeline UI.</p><h3>How It Works</h3><p>The architecture has three moving parts: an agentless DevOps Pipeline publishes a message to Azure Service Bus via <code>PublishToAzureServiceBus@1</code>, an Azure Function (<code>run_notebook_service_bus</code>) picks it up and orchestrates the run, and Azure ML Compute executes the notebook. The Function authenticates to the ML Workspace via Service Principal, fetches the target repository, injects try-catch callbacks around each notebook cell for completion signaling, submits Runs with configurable compute targets and Conda environments, and polls for results. When runs finish, the Function posts Test Run results, attachments, and status updates back to DevOps via the REST API, then closes the pipeline with a callback. A separate agent-based deployment pipeline handles <code>pytest</code> unit testing, packaging, and <code>AzureFunctionApp@1</code> deployment.</p><h3>The Grind</h3><p>The codebase is organized into focused handler modules ‚Äî <code>azureml_handler.py</code> (Workspace auth, Experiment/Run/RunConfig management), <code>devops_handler.py</code> (pipeline callbacks, Test Run CRUD, attachments, repository downloads), <code>file_handler.py</code> (staging, snapshot builds, Conda dependency injection, notebook callback injection/removal), and <code>notebook_handler.py</code> (cell-level code injection and scrubbing). Pipeline configuration is driven entirely by DevOps variables ‚Äî 20+ parameters covering Service Bus connections, compute targets, Docker images, repository versions, and Service Principal credentials. The result: notebook validation that runs faster, surfaces richer telemetry, supports custom images, and doesn't block on busy agent pools.</p>"
breeze,üí® Breeze,Keysight IoT Challenge,May 2019,"Merced, California",https://github.com/plebeiathon/Breeze,"Promoting Air Quality Awareness is a Breeze",,"<h3>The Idea</h3><p>Air quality monitoring shouldn't require expensive equipment or dedicated infrastructure. Breeze turns any smartphone into an IoT air quality sensor by plugging off-the-shelf sensors directly into the audio aux jack ‚Äî no Bluetooth pairing, no proprietary hardware, no app store downloads. Just plug in and start collecting data. A submission to Keysight's IoT Innovation Challenge.</p><h3>How It Works</h3><p>Sensor data streams through the aux jack into a web dashboard built on Paper Dashboard, where Mapbox GL JS renders real-time air quality heatmaps with interpolated color ramps ‚Äî blue for clean air, red for hazardous. Users can zoom from a global view down to street-level detail, with the heatmap transitioning to individual data point circles at higher zoom levels. The dashboard includes a Stats page for historical trends via Chartist.js charts and a My Device page for managing connected sensors.</p><h3>The Grind</h3><p>The clever part is the aux jack approach ‚Äî it sidesteps every barrier to IoT adoption. No wireless protocol configuration, no companion app installs, no battery-powered sensor nodes to maintain. Any phone with a headphone jack becomes a node in a distributed air quality network. We built the entire visualization layer from GeoJSON data sources with custom heatmap weight, intensity, radius, and opacity interpolations tuned by zoom level for a smooth, readable map at any scale.</p>"
ozone,üó† Ozone,Innovate to Grow,May 2018,"Merced, California",https://github.com/SSites/Ozone,"Providing access to sustainability initiatives in an interactive, hands-on manner",,"<h3>The Idea</h3><p>UC Merced's Department of Sustainability had no central way to show students, faculty, and visitors what green initiatives actually existed on campus ‚Äî or where to find them. Through Engineering Service Learning, we built Ozone: an interactive web app mapping every sustainability resource on campus, designed to eventually live at sustainability.ucmerced.edu/map.</p><h3>How It Works</h3><p>A React front-end with three themed Mapbox GL JS maps ‚Äî Environmental, Economic, and Social ‚Äî each rendering GeoJSON polygon overlays of every campus building. Point-of-interest markers are loaded from CSV data via Axios and PapaParse, covering water refill stations, Ozzi reusable container stations, LEED labs, EV charging, bike racks, community gardens, bus stops, gender-neutral bathrooms, and more. Each marker gets a unique Font Awesome icon and color, with popups showing descriptions and locations. The maps support geolocation tracking, navigation controls, and a 3D pitch toggle for building extrusions.</p><h3>The Grind</h3><p>Every building on UC Merced's campus is hand-mapped as a GeoJSON polygon with precise coordinates ‚Äî COB1, COB2, SE1, SE2, Mariposa, Tuolumne, Cathedral, Half Dome, Valley Terrace, the works. Three separate map components each load their own themed CSV datasets and render dozens of categorized markers with custom icon switching. Built on Node/Express with Jest testing, the app went from a service learning project to a real tool for the Department of Sustainability.</p>"
iterate,‚Ñπ Iterate,Mobile App Challenge,May 2017,"Merced, California",https://github.com/Mutilar/iterate,"The Rosetta Stone of Programming, taking the practical knowledge of Java and combining it with the ease of use of Scratch","$5,000 Grand Prize","<h3>The Idea</h3><p>Most people learn to code by staring at a blank text editor and failing ‚Äî or by dragging blocks in Scratch and never writing a real line of code. Iterate bridges that gap: a mobile code editor that uses Java/Arduino syntax but lets you build programs through guided tap-based selections instead of raw typing. Built for UC Merced's CITRIS Mobile App Challenge, the pitch was simple ‚Äî put real programming in everyone's pocket.</p><h3>How It Works</h3><p>Built in Unity with C#, the entire app runs on a 1,300+ line CodeManager that acts as both editor and interpreter. Users tap a line to enter edit mode, then construct code through cascading option menus: Create Variable ‚Üí Integer/Double/Boolean/String ‚Üí name it ‚Üí assign a value. Flow control (if/else, while, for loops), Arduino hardware calls (pinMode, digitalWrite, analogRead, analogWrite, Serial.begin/print/println, servo.attach/write, delay, map), and variable scoping are all handled through the same tap-driven UI. A ColorCoder class provides real-time syntax highlighting ‚Äî keywords in blue, objects in teal, strings in amber, comments in green ‚Äî by injecting Unity rich text color tags on every frame. Pre-built lesson templates (Windmill, Servos, Stopwatch) load from Resources as starting scaffolds.</p><h3>The Grind</h3><p>The editor tracks variable scope by scanning every line above the cursor for declarations, dynamically populating only the valid options at each step ‚Äî you literally can't write a syntax error. The whole thing compiles to WebGL so it runs in-browser on any device. We took the $5,000 Grand Prize at the 2017 CITRIS Mobile App Challenge, beating out every team in the UC system. <a href='https://iterateco.de' target='_blank'>Try it live ‚Üí</a></p>"
amaxesd,‚ö° AMAX ESD,"FIRST Robotics, AMAX",January 2015,"Fremont, California",,"Real-time ESD detection for AMAX's large-scale server manufacturing floor",,"<h3>The Idea</h3><p>Electrostatic discharge can silently kill server components ‚Äî failures that don't show up for years, well short of expected MTBF. As an ISO 9001 manufacturer building mission-critical servers for Fortune 500 brands, AMAX needed a way to catch ESD bracelet disconnections the instant they happen on a busy production floor. They brought the problem to FIRST Robotics Team 1458 (the Red Ties) and said: build us something real.</p><h3>How It Works</h3><p>We designed a system using standard ESD bracelets wired through analog ESD monitors with connectivity to LED light poles. The moment an operator's bracelet loses ground ‚Äî whether disconnected or improperly seated ‚Äî the light pole fires immediately, giving real-time, at-a-glance identification across the production floor. No software lag, no manual checks: automated monitoring that integrates directly into AMAX's existing assembly lines.</p><h3>The Grind</h3><p>High school students solving a real manufacturing problem for a real company. We went from theoretical classroom principles to engineering a product AMAX deployed on their production lines with immediate impact. As David Hungerman put it: 'This project took FRC one step further and allowed us to understand these principles in a real-world situation.' FIRST's Jim Beck called it 'a testament to the success of FIRST ‚Äî this is about more than robots.'</p>"
